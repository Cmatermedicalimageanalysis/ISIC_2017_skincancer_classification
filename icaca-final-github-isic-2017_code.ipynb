{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1150616,"sourceType":"datasetVersion","datasetId":649927},{"sourceId":6602304,"sourceType":"datasetVersion","datasetId":3809235},{"sourceId":6876576,"sourceType":"datasetVersion","datasetId":3951369},{"sourceId":6892933,"sourceType":"datasetVersion","datasetId":3959785},{"sourceId":6892955,"sourceType":"datasetVersion","datasetId":3959799},{"sourceId":7130181,"sourceType":"datasetVersion","datasetId":4113674},{"sourceId":7135853,"sourceType":"datasetVersion","datasetId":4117571}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf   \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array, load_img\nfrom tensorflow.keras.applications import ResNet50,Xception\nfrom tensorflow.keras.models import Sequential,Model   \nfrom tensorflow.keras.layers import Dense,Input, GlobalAveragePooling2D, Dense, Dropout, multiply, Reshape, Conv2D, Activation, Add, Dropout, GlobalAveragePooling2D, BatchNormalization, Multiply,MaxPooling2D,Concatenate,Conv2D, UpSampling2D, Cropping2D,Lambda\nfrom tensorflow.keras.optimizers import Adam\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler,ModelCheckpoint\n\nimport shutil\nfrom tensorflow.keras.preprocessing.image import array_to_img\nfrom tensorflow.keras.losses import categorical_crossentropy\nfrom tensorflow.keras.metrics import Accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt    \nimport matplotlib.image as mpimg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the image size and batch size for training\nbatch_size =16","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define input shape \ninput_shape = (400,400,3)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset_dir='/kaggle/input/isic-2017-preprocessed-augmented/content/Linear_Exact_Aug/Train'   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Valid_dataset_dir='/kaggle/input/isic-2017-preprocessed-augmented/content/Linear_Exact_Aug/Valid'   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data augmentation and normalization for training\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0 / 255.0,  \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the training dataset with data augmentation\ntrain_generator = train_datagen.flow_from_directory(\n    train_dataset_dir,   \n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset_dir = '/kaggle/input/isic-2017-preprocessed-augmented/content/Linear_Exact_Aug/Test' ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntest_data_generator = ImageDataGenerator(\n    rescale=1.0/255.0,  # Normalize pixel values to the range [0, 1]\n    # Add any other preprocessing options if needed\n)\n\ntest_generator = test_data_generator.flow_from_directory(\n    test_dataset_dir,    \n    target_size=(400,400),  # Adjust to match your model's input size\n    batch_size=16,           # Adjust batch size as needed   \n    class_mode='categorical',  # If you have class labels\n    shuffle=False              # Do not shuffle test data\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data normalization for validation and testing\nval_datagen = ImageDataGenerator(rescale=1.0 / 255.0)   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the validation dataset\nval_generator = val_datagen.flow_from_directory(\n    Valid_dataset_dir,   \n    target_size=input_shape[:2],\n    batch_size=batch_size,    \n    class_mode='categorical'\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create an input layer\ninput_layer = Input(shape=input_shape)   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_hub as hub    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bit_l_url = \"https://tfhub.dev/google/bit/m-r101x1/1\"   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the BiT L model from TensorFlow Hub\nbit_l_model = hub.KerasLayer(bit_l_url, trainable=True)\nbit_l_output = bit_l_model(input_layer)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bit_l_output_reshaped = Reshape((1, 1, -1))(bit_l_output)  # Reshape to match the expected shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the Xception model without top classification layers\nxception_base_model = Xception(weights='imagenet', include_top=False, input_shape=input_shape)\nfor layer in xception_base_model.layers:\n    layer.trainable = True     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Connect the input layer to the base models\nxception_features = xception_base_model(input_layer)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_features =multiply([xception_features,bit_l_output_reshaped])   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply Squeeze-and-Excitation block\ndef se_block(input_tensor):   \n    num_channels = input_tensor.shape[-1]\n    \n    # Squeeze operation (Global Average Pooling)\n    squeeze = GlobalAveragePooling2D()(input_tensor)\n    squeeze = Reshape((1, 1, num_channels))(squeeze)\n    \n    # Excitation operation (Fully connected layers)\n    excitation = Dense(num_channels // 16, activation='relu')(squeeze)\n    excitation = Dense(num_channels, activation='sigmoid')(excitation)\n    \n    # Scale the input feature maps\n    scaled_features = multiply([input_tensor, excitation])\n    \n    return scaled_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"se_output = se_block(combined_features)\n   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add a classification head to the combined features\nfrom tensorflow.keras.regularizers import l2\nx = tf.keras.layers.GlobalAveragePooling2D()(se_output)\nx = tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=l2(0.01))(x)\nx = Dropout(0.1)(x)\nx = tf.keras.layers.Dense(2048, activation='relu')(x)\nx = tf.keras.layers.Dense(512, activation='selu',kernel_regularizer=l2(0.02))(x)\nx = BatchNormalization()(x)\noutput = tf.keras.layers.Dense(3, activation='softmax')(x)  # 7output classes\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the ensemble model\nmodel = Model(inputs=input_layer, outputs=output)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.utils import plot_model\n\n# Define your model here\nmodel = model\n\n# Specify the file path where you want to save the model architecture image\nimage_path = 'model_architecture.png'\n\n# Plot the model architecture and save it as an image\nplot_model(model, to_file=image_path, show_shapes=True, show_layer_names=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.losses import categorical_crossentropy\n\ndef combined_loss(y_true, y_pred, alpha=0.2, categorical_weight=0.5):\n    # Compute the categorical cross-entropy loss\n    cat_loss = categorical_crossentropy(y_true, y_pred)\n\n    # Reshape the inputs to get anchor, positive, and negative examples\n    anchor = tf.reshape(y_pred[:, 0], shape=(-1, 1))\n    positive = tf.reshape(y_pred[:, 1], shape=(-1, 1))\n    negative = tf.reshape(y_pred[:, 2], shape=(-1, 1))\n\n    # Compute the distance between the anchor and the positive\n    pos_distance = tf.reduce_sum(tf.square(anchor - positive), axis=1)\n    \n    # Compute the distance between the anchor and the negative\n    neg_distance = tf.reduce_sum(tf.square(anchor - negative), axis=1)\n\n    # Compute the triplet loss\n    triplet_basic_loss = pos_distance - neg_distance + alpha\n    triplet_loss = tf.reduce_mean(tf.maximum(triplet_basic_loss, 0.0), axis=0)\n\n    # Compute the combined loss\n    combined_loss = categorical_weight * cat_loss + (1 - categorical_weight) * triplet_loss\n\n    return combined_loss\n\n# Example usage in a Keras model\nmodel.compile(optimizer='adam', loss=combined_loss, metrics=['accuracy'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Implement learning rate scheduling   \nlr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Define the model checkpoint callback to save the best weights\nmodel_checkpoint = ModelCheckpoint('ISIC2017_Classification_contour_ensemble5.h5', monitor='val_accuracy', save_best_only=True, save_weights_only=True, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Implement early stopping\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience=30, verbose=1, restore_best_weights=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nepochs =30\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // 32,\n    epochs=epochs,   \n    validation_data=val_generator,\n    validation_steps=val_generator.samples // 32,\n    callbacks=[lr_scheduler,model_checkpoint,early_stopping]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training and validation accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training and validation loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')   \nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n#Load the saved weights from the output directory in the executed model architecture .  \nmodel.load_weights('/kaggle/working/ISIC2017_Classification_contour_ensemble5.h5')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(test_generator)\nprint(f\"Test Loss: {test_loss}\")    \nprint(f\"Test Accuracy: {test_accuracy}\")\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n#  the true labels and predicted labels for the test dataset\ny_true = test_generator.classes\ny_pred = model.predict(test_generator).argmax(axis=1)\n   \n# Compute the confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n    \n# Plot the confusion matrix\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_generator.class_indices.keys())\ndisp.plot(cmap='viridis')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = {0:'melanoma', 1:'nevus', 2:'seborrheic_keratosis'}\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import classification_report\ncm = confusion_matrix(y_true, y_pred)\ncmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]   \nfig, ax = plt.subplots(figsize=(8,6))  \nsns.heatmap(cmn, annot=True, xticklabels=labels.values(), yticklabels=labels.values(),cmap=plt.cm.Blues, fmt='.2f')\nplt.ylabel('Actual Classes')\nplt.xlabel('Predicted Classes')\nplt.show(block=False)    \n   \n# Generate the classification report\nreport = classification_report(y_true, y_pred)\n\nprint(\"Confusion Matrix:\")\nprint(cm)    \nprint(report)     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\nprint(\"Precision: \"+ str(precision_score(y_true, y_pred, average='weighted')))\nprint(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\nprint(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\nf1 = f1_score(y_true, y_pred, average='weighted')\nprint(\"F1 Score: \" + str(f1))\n     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='macro')))\nprint(\"Recall: \"+ str(recall_score(y_true, y_pred, average='macro')))\nprint(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\nf1 = f1_score(y_true, y_pred, average='macro')\nprint(\"F1 Score: \" + str(f1))\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='micro')))\nprint(\"Recall: \"+ str(recall_score(y_true, y_pred, average='micro')))\nprint(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\nf1 = f1_score(y_true, y_pred, average='micro')\nprint(\"F1 Score: \" + str(f1))\n         ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\ny_true = test_generator.classes   \n# Get the probabilities for each class (0 and 1) from the model predictions\ny_prob = model.predict(test_generator)\n\n# Compute the ROC curve for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(train_generator.num_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_true == i, y_prob[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n   \n# Plot the ROC curves\nplt.figure()\nfor i in range(train_generator.num_classes):\n    plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score    \nprint(\"weighted Roc score: \" + str(roc_auc_score(y_true,y_prob,multi_class='ovr',average='weighted')))\nprint(\"macro Roc score: \" + str(roc_auc_score(y_true,y_prob,multi_class='ovr',average='macro')))    \nprint(\"micro Roc score: \" + str(roc_auc_score(y_true,y_prob,multi_class='ovr',average='micro')))  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}